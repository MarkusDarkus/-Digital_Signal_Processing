"""
На практике встречаются задачи, 
когда производились измерения 
некоторой функциональной зависимости,
 но из-за погрешностей приборов, 
или неточных сведений или еще по 
какой-либо причине, измерения немного 
отстоят от истинных значений функции 
и образуют некий разброс.

Так вот, в методе наименьших квадратов
 используется минимум суммы квадратов ошибок.

 Здесь все также, нужно взять частные производные
   по каждому параметру и приравнять результат нулю, 
   получим систему линейных уравнений

Решая систему получаем значения коэффициентов,
получая лучшую апркоксимацию по критерию
минимума суммарной квадратичной ошибки отклонений

РЕАЛИЗАЦИЯ:::
"""

#!pip install numpy / matplotlib

import numpy as np
import matplotlib.pyplot as plt

N = 100     # число экспериментов
sigma = 3   # стандартное отклонение наблюдаемых значений
k = 0.5     # теоретическое значение параметра k
b = 2   # теоретичесукое значение параметра b

x = np.array(range(N)) #Формируем вспомогательный вектор
f = np.array([k*z+b for z in range(N)]) #вычисляем значения теоретической функции:

y = f + np.random.normal(0, sigma, N) #Добавили шум

#вычисляем коэффициенты
mx = x.sum()/N
my = y.sum()/N
a2 = np.dot(x.T, x)/N
a11 = np.dot(x.T, y)/N

kk = (a11 - mx*my)/(a2 - mx**2)
bb = my - kk*mx

#построим точки апркосимации
ff = np.array([kk*z+bb for z in range(N)])

plt.plot(f)
plt.plot(ff, c='red')
plt.show()


